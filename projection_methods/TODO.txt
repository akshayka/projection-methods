- redo old experiments (SOC, R) [i.e., no zero cones]
- here's a weird idea: a meta-solver that runs N APOPs in parallel, and each
  APOP shares with the others the cutting planes it recovers.
- here's another weird idea: merge apop and altpop, in the sense that use
  both the halfspaces obtained from apop and the halfspaces obtained from
  altpop

- over-relaxation
- over-projection
- multiple state variables
- run new LP, make sure cone_dims is right, make sure cones are right
- tests: dynamic_polyhedron, cartesianproduct

- return halfspaces instead of hyperplanes for the affine set?

*** Experiment: Rerun experiments, keeping the zero hyperplane in the
dynamic polyhedron *** [P0]
----- the linear search is way too expensive; is this because of the sparse
1000 * 1000 matrix?

*** Polish the result returned by SCS -- either switch to APOP after
    sufficient progress has been made, or project onto the cutting planes
    that were produced during the previous N iterations. *** [P0]

*** Investigate: Can we do things like line searches or keeping multiple states
    to accelerate APOP further? It is currently worse than ADMM. *** [P1]

*** Theorize: Can we incorporate a momentum-like construction into our update
directions in a principled manner? *** [P2]

*** Add the zero duality gap constraint to the set of hyperplanes when solving
    SCSProblems *** [P1] 

*** Investigate: Can we accelerate ADMM instead of accelerating AP? *** [P1]

*** Change default atol from 1e-4 to 1e-3 in experiment.py *** [P1]

*** Root-cause core dump when running apop avg on znss_m_2000_n_1000.pkl *** [P1]

*** Perform a line search during the localization step *** [P2]

*** What's the deal with zero cones? can't we just do a presolve and get rid
    of variables that are known to be zero? *** [P2]
----- perhaps eliminating it breaks the avoidance of zero (ie, perhaps iterates
      may converge to zero, even if a non-zero solution exists, when the
      zero cones are eliminated).
----- double check with boyd that eliminating zero cones in outer projection is
      fine
----- Boyd did say that we could probably eliminate the zero cones

*** Scale to larger problems *** [P3]
----- for example, the "small" random problem in the SCS paper


~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~
completed tasks
- implement save_problem
- write plotting code
- implement projection onto affine set as a (factorized) sparse matrix solve
- cook up harder problems (convergence should not happen after one iteration!)
- implement SCS problem in problem_factory

*** Bug fix: the oracle for the zero cone only returns information the first
time it is queried. thereafter it does not return anything! This should not be
the case, as we are losing valuable information as a result. The zero cone
should return the hyperplane every time, and dynamic polyhedron should refuse
to add a hyperplane / halfspace it already has *** [P0]

*** Implement ADMM as per SCS *** [P1]
----- apply to the random cone program
----- compare with AP/Dykstra [P1]

*** Implement linear program a la SCS embedding *** [P0]

*** Root-cause bug that results in objective value < optimal value (SCS) *** [P0]
----- see bugs.txt
----- Note that a single SOC still works (obj value >= opt value)
> it appears that this issue is not really an issue -- if the objective
> value < optimal value, it must be the case that the iterate in question
> is not feasible; that is what appeared to happen

*** Why are some problems (1000_s.pkl, for example) solved after just one
    iteration? ***
----  I suppose the initial iterate was in fact in the SOC.
> 1000_s was solved in one iteration because there was exactly one solution;
> the others may have simply been too easy

** check values of kappa and tau **
--- why on earth would tau == 0, kappa > 0, but c.t(x) + b.t(y) < 0? that cannot
    happen.
> done; this was a bug in my generation of random cone programs (Q_tilde was
> wrong)

** why do residuals increase for the random_socp problem?! **
---- perhaps I introduced a bug in my recently added code
---- check nonneg.py, for example
> done; same as above
    
*** If a portion of x lies in the zero cone, can we add that constraint to
    for exaple our outer projections and still solve them efficiently?
----- sure; this just amounts to eliminating some variables, I think.
> my answer is yes; this is just an elimination

*** what is a correct way to measure residuals for all three algorithms? ***
----- the sum of the distances from the iterate to both the left and right sets
      feels very suboptimal. For example, if the two sets were hyperplanes that
      were almost parallel, then this sum could be very small even when the
      iterate were very far from the intersection of the two hyperplanes.
> [Done -- the distance from the two sets is fine]

*** why does apop_exact diverge after a certain number of iterations? ***
----- could it be numerical instability? for example, a halfspace is added that
      takes the iterates way out of the optimal set?
----- whatever is happening, it is still the case that every outer approximation
      problem is feasible
----- due to numerical instability, it is possible that an untrue statement
      (i.e., a hyperplane of the form { x | a.dot(x) == b } that is _not_
      a superset (nor a subset) of the affine set, or similarly a halfspace
      that is _not_ a superset (nor a subset) of the convex set; if this were
      to happen, then the outer projection would not necessarily bring the
      iterate closer to the optimal set (in particular, convergence guarantees
      would be lost)
----- it is also possible that my code / math for computing containing
      hyperplanes and halfspaces is not correct, or that my code for, e.g.,
      projecting onto an SOC is incorrect
----- it _may_ have been a pickling issue. the class definitions for many of
      the oracles and projectables changed after the object had been pickled.
      scrapping the old problem and generating a new one has "solved" the issue,
      insofar as apop (exact) generates a reasonable sequence of iterates
      when solving a similar problem (problem name 2550_rszs); however, the
      residuals are embarassingly high (> 0.1). it is not clear if the issue
      has been corrected, or if it has simply been hidden.
> [Done -- it was a pickling issue]
